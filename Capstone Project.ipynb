{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Capstone Project: ETL Pipeline for Fire Department Calls and Temperature Data\n",
    "\n",
    "## Project Summary\n",
    "The goal of this project: \n",
    "* Download San Francisco Fire department Calls-For-Service data and globle land city temperature data from Kaggle and load raw dataset to AWS S3, \n",
    "* Create an ETL pipeline that extracts data, processes data using Spark, and loads the data back into set of dimensional tables in S3. <br>\n",
    "\n",
    "This will allow analytics team to find insights of the fire calls-for-service.e.g.\n",
    "* What were the common types of fire calls?<br> \n",
    "* Which months within the year 2019 saw for the highest number of fire calls? <br>\n",
    "* How to improve in order to reduce the fire incident?<br>\n",
    "* Does temperature affect the fire incidents?<br>\n",
    "\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data<br>\n",
    "* Step 2: Explore and Assess the Data<br>\n",
    "* Step 3: Define the Data Model<br>\n",
    "* Step 4: Run ETL to Model the Data<br>\n",
    "* Step 5: Complete Project Write Up<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import configparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Set AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read_file(open('aws/dl.cfg'))\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope\n",
    "In this project, we will aggregate fire call data by CallType to form first dimension table. Next we will aggregate city temperature data by year and month to form the second dimension table. The two datasets will be joined on city, year and month to form the fact table. The final database is optimized to query on fire call events to determine if temperature affects the number of fire incidents. Spark will be used to process the data.\n",
    "\n",
    " \n",
    "### Describe and Gather Data\n",
    "**Data Source 1** <br>\n",
    "San Francisco Fire Calls-For-Service <br>\n",
    "https://www.kaggle.com/san-francisco/sf-fire-data-incidents-violations-and-more\n",
    "    \n",
    "**Content** <br>\n",
    "Fire Calls-For-Service includes all fire units responses to calls. Each record includes the call number, incident number, address, unit identifier, call type, and disposition. All relevant time intervals are also included.\n",
    "\n",
    "**Data Source 2**<br>\n",
    "\n",
    "https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data?select=GlobalLandTemperaturesByCity.csv\n",
    "The temperature data comes from Kaggle. It is provided in csv format. Some relevant attributes include:\n",
    "\n",
    "**Content** <br>\n",
    "AverageTemperature = average temperature\n",
    "City = city name\n",
    "Country = country name\n",
    "Latitude= latitude\n",
    "Longitude = longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read in fire calls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319351"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the fire calls data \n",
    "# input_path = \"input/fire-department-calls-for-service.csv\"\n",
    "\n",
    "input_path = \"s3a://udacity-dend-capstone-project/firecall_data/\"\n",
    "fire_df =spark.read.csv(input_path, header=True, mode=\"DROPMALFORMED\")\n",
    "fire_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Call Number: string (nullable = true)\n",
      " |-- Unit ID: string (nullable = true)\n",
      " |-- Incident Number: string (nullable = true)\n",
      " |-- Call Type: string (nullable = true)\n",
      " |-- Call Date: string (nullable = true)\n",
      " |-- Watch Date: string (nullable = true)\n",
      " |-- Received DtTm: string (nullable = true)\n",
      " |-- Entry DtTm: string (nullable = true)\n",
      " |-- Dispatch DtTm: string (nullable = true)\n",
      " |-- Response DtTm: string (nullable = true)\n",
      " |-- On Scene DtTm: string (nullable = true)\n",
      " |-- Transport DtTm: string (nullable = true)\n",
      " |-- Hospital DtTm: string (nullable = true)\n",
      " |-- Call Final Disposition: string (nullable = true)\n",
      " |-- Available DtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode of Incident: string (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- Station Area: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- Original Priority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- Final Priority: string (nullable = true)\n",
      " |-- ALS Unit: string (nullable = true)\n",
      " |-- Call Type Group: string (nullable = true)\n",
      " |-- Number of Alarms: string (nullable = true)\n",
      " |-- Unit Type: string (nullable = true)\n",
      " |-- Unit sequence in call dispatch: string (nullable = true)\n",
      " |-- Fire Prevention District: string (nullable = true)\n",
      " |-- Supervisor District: string (nullable = true)\n",
      " |-- Neighborhooods - Analysis Boundaries: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Supervisor Districts: string (nullable = true)\n",
      " |-- Fire Prevention Districts: string (nullable = true)\n",
      " |-- Current Police Districts: string (nullable = true)\n",
      " |-- Neighborhoods - Analysis Boundaries: string (nullable = true)\n",
      " |-- Zip Codes: string (nullable = true)\n",
      " |-- Neighborhoods (old): string (nullable = true)\n",
      " |-- Police Districts: string (nullable = true)\n",
      " |-- Civic Center Harm Reduction Project Boundary: string (nullable = true)\n",
      " |-- HSOC Zones: string (nullable = true)\n",
      " |-- Central Market/Tenderloin Boundary Polygon - Updated: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read in temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in temperature data\n",
    "# temperature_input_path = \"input/GlobalLandTemperaturesByCity.csv\"\n",
    "\n",
    "temperature_input_path = \"s3a://udacity-dend-capstone-project/temp_data/\"\n",
    "df_t =spark.read.csv(temperature_input_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|dt        |AverageTemperature|AverageTemperatureUncertainty|City |Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|6.068             |1.7369999999999999           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1743-12-01|null              |null                         |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-01-01|null              |null                         |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-02-01|null              |null                         |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-03-01|null              |null                         |Århus|Denmark|57.05N  |10.33E   |\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_t.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Cleaning the data\n",
    "For the temperature data,  drop all entries where AverageTemperature is NaN, then add year and month as new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|dt        |AverageTemperature|AverageTemperatureUncertainty|City |Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|6.068             |1.7369999999999999           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-04-01|5.7879999999999985|3.6239999999999997           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-05-01|10.644            |1.2830000000000001           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-06-01|14.050999999999998|1.347                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-07-01|16.082            |1.396                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out entries with NaN average temperature\n",
    "df_t=df_t.filter(df_t.AverageTemperature != 'NaN')\n",
    "df_t.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8235082"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove duplicate locations\n",
    "df_t=df_t.dropDuplicates(['dt', 'City', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8190783"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add 2 new columns \"year\" and \"month\" to df_t\n",
    "df_t = df_t.withColumn(\"year\", F.year(df_t.dt)) \\\n",
    "                 .withColumn(\"month\", F.month(df_t.dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----------+-------+--------+---------+----+-----+\n",
      "|dt        |AverageTemperature|AverageTemperatureUncertainty|City       |Country|Latitude|Longitude|year|month|\n",
      "+----------+------------------+-----------------------------+-----------+-------+--------+---------+----+-----+\n",
      "|1743-11-01|7.03              |1.611                        |Bielefeld  |Germany|52.24N  |7.88E    |1743|11   |\n",
      "|1743-11-01|7.318             |1.764                        |Kaliningrad|Russia |55.45N  |19.84E   |1743|11   |\n",
      "+----------+------------------+-----------------------------+-----------+-------+--------+---------+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_t.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Query temperature info for city \"San Francisco\"\n",
    "df_t_san = (df_t.select('dt','year','month', 'Country', 'City', \"AverageTemperature\").where(df_t.City == \"San Francisco\")).sort('dt',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+-------------+-------------+------------------+\n",
      "|        dt|year|month|      Country|         City|AverageTemperature|\n",
      "+----------+----+-----+-------------+-------------+------------------+\n",
      "|2013-09-01|2013|    9|United States|San Francisco|            20.471|\n",
      "|2013-08-01|2013|    8|United States|San Francisco|19.730999999999998|\n",
      "|2013-07-01|2013|    7|United States|San Francisco|20.656999999999996|\n",
      "|2013-06-01|2013|    6|United States|San Francisco|            19.759|\n",
      "|2013-05-01|2013|    5|United States|San Francisco|            17.434|\n",
      "|2013-04-01|2013|    4|United States|San Francisco|15.995999999999999|\n",
      "|2013-03-01|2013|    3|United States|San Francisco|13.505999999999998|\n",
      "|2013-02-01|2013|    2|United States|San Francisco|            10.229|\n",
      "|2013-01-01|2013|    1|United States|San Francisco|              8.32|\n",
      "|2012-12-01|2012|   12|United States|San Francisco|              8.95|\n",
      "|2012-11-01|2012|   11|United States|San Francisco|            13.367|\n",
      "|2012-10-01|2012|   10|United States|San Francisco|17.294999999999998|\n",
      "|2012-09-01|2012|    9|United States|San Francisco|            19.045|\n",
      "|2012-08-01|2012|    8|United States|San Francisco|            20.531|\n",
      "|2012-07-01|2012|    7|United States|San Francisco|            19.632|\n",
      "|2012-06-01|2012|    6|United States|San Francisco|            18.482|\n",
      "|2012-05-01|2012|    5|United States|San Francisco|            16.555|\n",
      "|2012-04-01|2012|    4|United States|San Francisco|             14.15|\n",
      "|2012-03-01|2012|    3|United States|San Francisco|            11.503|\n",
      "|2012-02-01|2012|    2|United States|San Francisco|            11.116|\n",
      "|2012-01-01|2012|    1|United States|San Francisco|             9.993|\n",
      "|2011-12-01|2011|   12|United States|San Francisco|             9.118|\n",
      "|2011-11-01|2011|   11|United States|San Francisco|            11.478|\n",
      "|2011-10-01|2011|   10|United States|San Francisco|17.294999999999998|\n",
      "+----------+----+-----+-------------+-------------+------------------+\n",
      "only showing top 24 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_t_san.show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.1 Conceptual Data Model\n",
    "The first dimension table will contain events from the fire department calls data. The columns below will be extracted from the fire calls dataframe:\n",
    "\n",
    ">CallNumber<br>\n",
    ">City<br>\n",
    ">CallType<br>\n",
    ">Callyear<br>\n",
    ">callmonth<br>\n",
    ">Neighborhooods-AnalysisBoundaries<br>\n",
    ">received_dt<br>\n",
    ">available_dt<br>\n",
    "       \n",
    "The second dimension table will contain city temperature data. The columns below will be extracted from the temperature dataframe:\n",
    ">ts<br>\n",
    ">year<br>\n",
    ">month<br>\n",
    ">AverageTemperature <br>\n",
    ">City <br>\n",
    ">Country <br>\n",
    "\n",
    "The fact table will contain information from the fire calls data joined with the city temperature data on City:\n",
    "\n",
    ">CallNumber<br>\n",
    ">City<br>\n",
    ">CallType<br>\n",
    ">year<br>\n",
    ">month<br>\n",
    ">AverageTemperature<br>\n",
    ">Country<br>\n",
    ">dt<br>\n",
    "\n",
    "\n",
    "The tables will be saved to Parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.2 Mapping Out Data Pipelines\n",
    "The pipeline steps are described below:\n",
    "    \n",
    "* Clean temperature calls data as described in step 2 to create Spark dataframe df_temp\n",
    "* Create fire call dimension table by selecting columns from df_fire and write to parquet file\n",
    "* Create temperature dimension table by selecting columns from df_temp and write to parquet file partitioned\n",
    "* Create fact table by joining fire and temperature dimension tables on [city, year, month] and write to parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fire_table = fire_df.select(\"Call Number\", \"Call Date\", \"Call Type\" , \"City\", \"Neighborhooods - Analysis Boundaries\", \"Received DtTm\", \"Available DtTm\" )\\\n",
    "                        .withColumn(\"year\", F.year(\"Call Date\")) \\\n",
    "                        .withColumn(\"month\", F.month(\"Call Date\")) \\\n",
    "                        .withColumnRenamed(\"Call Number\", \"callnumber\") \\\n",
    "                        .withColumnRenamed(\"Call Date\", \"calldate\") \\\n",
    "                        .withColumnRenamed(\"Call Type\", \"calltype\") \\\n",
    "                        .withColumnRenamed(\"Neighborhooods - Analysis Boundaries\", \"Neighborhooods\") \\\n",
    "                        .withColumnRenamed(\"Received DtTm\", \"received_dt\") \\\n",
    "                        .withColumnRenamed(\"Available DtTm\", \"available_dt\") \\\n",
    "                        .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+----------------+-------------+------------------------------------+-----------------------+-----------------------+----+-----+\n",
      "|Call Number|Call Date              |Call Type       |City         |Neighborhooods - Analysis Boundaries|Received DtTm          |Available DtTm         |year|month|\n",
      "+-----------+-----------------------+----------------+-------------+------------------------------------+-----------------------+-----------------------+----+-----+\n",
      "|201903333  |2020-07-08T00:00:00.000|Medical Incident|San Francisco|Tenderloin                          |2020-07-08T23:08:23.000|2020-07-08T23:27:53.000|2020|7    |\n",
      "|201903063  |2020-07-08T00:00:00.000|Structure Fire  |San Francisco|Outer Richmond                      |2020-07-08T20:53:55.000|2020-07-08T21:18:31.000|2020|7    |\n",
      "|201901433  |2020-07-08T00:00:00.000|Medical Incident|San Francisco|Bayview Hunters Point               |2020-07-08T12:22:43.000|2020-07-08T12:44:13.000|2020|7    |\n",
      "|201900691  |2020-07-08T00:00:00.000|Medical Incident|San Francisco|Tenderloin                          |2020-07-08T08:55:13.000|2020-07-08T09:55:18.000|2020|7    |\n",
      "|201892559  |2020-07-07T00:00:00.000|HazMat          |San Francisco|Financial District/South Beach      |2020-07-07T18:13:01.000|2020-07-07T19:00:37.000|2020|7    |\n",
      "+-----------+-----------------------+----------------+-------------+------------------------------------+-----------------------+-----------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_table.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "received_timetable = fire_df.select(\n",
    "                                F.col(\"Received DtTm\").alias(\"received_time\"),\n",
    "                                F.year(\"Received DtTm\").alias('year'),\n",
    "                                F.month(\"Received DtTm\").alias('month'),\n",
    "                                F.dayofmonth(\"Received DtTm\").alias('day'),\n",
    "                                F.hour(\"Received DtTm\").alias(\"hour\"),\n",
    "                                F.minute(\"Received DtTm\").alias(\"minute\"),\n",
    "                                F.second(\"Received DtTm\").alias(\"second\"),\n",
    "                                F.weekofyear(\"Received DtTm\").alias(\"week\"),\n",
    "                                F.date_format(F.col(\"Received DtTm\"), \"E\").alias(\"weekday\")\n",
    "                                ).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+-----+---+----+------+------+----+-------+\n",
      "|received_time          |year|month|day|hour|minute|second|week|weekday|\n",
      "+-----------------------+----+-----+---+----+------+------+----+-------+\n",
      "|2020-07-08T16:06:09.000|2020|7    |8  |16  |6     |9     |28  |Wed    |\n",
      "|2020-07-08T07:55:06.000|2020|7    |8  |7   |55    |6     |28  |Wed    |\n",
      "|2020-07-08T02:03:35.000|2020|7    |8  |2   |3     |35    |28  |Wed    |\n",
      "|2020-07-07T16:57:30.000|2020|7    |7  |16  |57    |30    |28  |Tue    |\n",
      "|2020-07-07T13:00:33.000|2020|7    |7  |13  |0     |33    |28  |Tue    |\n",
      "+-----------------------+----+-----+---+----+------+------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "received_timetable.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "available_timetable = fire_df.select(\n",
    "                                F.col(\"Available DtTm\").alias(\"available_time\"),\n",
    "                                F.year(\"Available DtTm\").alias('year'),\n",
    "                                F.month(\"Available DtTm\").alias('month'),\n",
    "                                F.dayofmonth(\"Available DtTm\").alias('day'),\n",
    "                                F.hour(\"Available DtTm\").alias(\"hour\"),\n",
    "                                F.minute(\"Available DtTm\").alias(\"minute\"),\n",
    "                                F.second(\"Available DtTm\").alias(\"second\"),\n",
    "                                F.weekofyear(\"Available DtTm\").alias(\"week\"),\n",
    "                                F.date_format(F.col(\"Available DtTm\"), \"E\").alias(\"weekday\")\n",
    "                                ).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+-----+---+----+------+------+----+-------+\n",
      "|available_time         |year|month|day|hour|minute|second|week|weekday|\n",
      "+-----------------------+----+-----+---+----+------+------+----+-------+\n",
      "|2020-07-08T20:54:28.000|2020|7    |8  |20  |54    |28    |28  |Wed    |\n",
      "|2020-07-08T19:53:37.000|2020|7    |8  |19  |53    |37    |28  |Wed    |\n",
      "|2020-07-08T17:52:20.000|2020|7    |8  |17  |52    |20    |28  |Wed    |\n",
      "|2020-07-08T12:27:52.000|2020|7    |8  |12  |27    |52    |28  |Wed    |\n",
      "|2020-07-08T12:27:08.000|2020|7    |8  |12  |27    |8     |28  |Wed    |\n",
      "+-----------------------+----+-----+---+----+------+------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "available_timetable.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----------+-------------+--------+---------+----+-----+\n",
      "|dt        |AverageTemperature|AverageTemperatureUncertainty|City       |Country      |Latitude|Longitude|year|month|\n",
      "+----------+------------------+-----------------------------+-----------+-------------+--------+---------+----+-----+\n",
      "|1743-11-01|7.03              |1.611                        |Bielefeld  |Germany      |52.24N  |7.88E    |1743|11   |\n",
      "|1743-11-01|7.318             |1.764                        |Kaliningrad|Russia       |55.45N  |19.84E   |1743|11   |\n",
      "|1743-11-01|3.544             |1.764                        |Mulhouse   |France       |47.42N  |8.29E    |1743|11   |\n",
      "|1743-11-01|18.722            |2.302                        |Orlando    |United States|28.13N  |80.91W   |1743|11   |\n",
      "|1743-11-01|6.425             |1.6280000000000001           |Remscheid  |Germany      |50.63N  |6.34E    |1743|11   |\n",
      "+----------+------------------+-----------------------------+-----------+-------------+--------+---------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_t.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_table = df_t.select(\"dt\", \"year\", \"month\",\"City\", \"Country\", \"AverageTemperature\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- callnumber: string (nullable = true)\n",
      " |-- calldate: string (nullable = true)\n",
      " |-- calltype: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Neighborhooods: string (nullable = true)\n",
      " |-- received_dt: string (nullable = true)\n",
      " |-- available_dt: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the fact table by joining the fire calls and temperature views\n",
    "fact_joined_table = fire_table.join(temperature_table, [\"City\", \"year\", \"month\"], how='inner')\n",
    "fire_temp_table = fact_joined_table.select(\"callnumber\", \"City\", \"calltype\", \"year\", \"month\", \"dt\",\"AverageTemperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------------+----+-----+----------+------------------+\n",
      "|callnumber|City         |calltype        |year|month|dt        |AverageTemperature|\n",
      "+----------+-------------+----------------+----+-----+----------+------------------+\n",
      "|010120303 |San Francisco|Medical Incident|2001|1    |2001-01-01|8.516             |\n",
      "+----------+-------------+----------------+----+-----+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_temp_table.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Write to AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write table to parquet file\n",
    "# fire_table.write.parquet(\"/results/firecall.parquet\")\n",
    "\n",
    "output_data  = \"s3a://udacity-dend-capstone-project/results\" \n",
    "\n",
    "received_timetable.write.parquet(output_data + \"received_time/\" + \"received_time.parquet\")\n",
    "available_timetable.write.parquet(output_data + \"available_time/\" + \"available_time.parquet\")\n",
    "\n",
    "fire_table.write.parquet(output_data + \"firecalls/\" + \"firecall.parquet\")\n",
    "temperature_table.write.parquet(output_data + \"temp/\" + \"temperature.parquet\")\n",
    "fire_temp_table.write.parquet(output_data + \"fire_temp/\" + \"fire_temp.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "\n",
    "def quality_check(df, description):\n",
    "    '''\n",
    "    Input: Spark dataframe\n",
    "    Output: Print outcome of data quality check\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(description, result))\n",
    "    return 0\n",
    "\n",
    "# Perform data quality check\n",
    "quality_check(fire_table, \"fire calls table\")\n",
    "quality_check(temperature_table, \"temperature table\")\n",
    "quality_check(fire_temp_table, \"fire calls and temperature joined table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.3 Data dictionary \n",
    "**fire calls table**\n",
    "* CallNumber: A unique 9-digit number assigned by the 911 Dispatch Center (DEM) to this call. These number are used for both Police and Fire calls.<br>\n",
    "* City: name of city<br>\n",
    "* CallType: the type of the call<br>\n",
    "* year: 4 digit year<br>\n",
    "* month: numeric month<br>\n",
    "* Neighborhooods-AnalysisBoundaries : Text, Neighborhood District associated with this address<br>\n",
    "* received_dt: Date and time of call is received at the 911 Dispatch Center.<br>\n",
    "* available_dt: Date and time this unit is not longer assigned to this call and it is available for another dispatch.<br>\n",
    "       \n",
    "**temperature data table**\n",
    "* ts: Date and time\n",
    "* year: 4 digit year<br>\n",
    "* month:numeric month<br>\n",
    "* AverageTemperature: Float, average temperature <br>\n",
    "* City:Name of city<br> <br>\n",
    "\n",
    "**joined table**\n",
    "\n",
    "* CallNumber: A unique 9-digit number assigned by the 911 Dispatch Center (DEM) to this call. These number are used for both Police and Fire calls.<br>\n",
    "* City: name of city<br>\n",
    "* CallType: Text, type of call\n",
    "* year:  4 digit year<br>\n",
    "* month: numeric month<br>\n",
    "* AverageTemperature: average temperature<br>\n",
    "* Country:name of country<br>\n",
    "* dt: Date and time<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "Spark was chosen since it can easily handle large amounts of data. <br> <br>\n",
    "\n",
    "* Propose how often the data should be updated and why.<br>\n",
    "The data should be updated monthly.<br> <br> \n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.<br>\n",
    " Use AWS EMR + S3 if the data was increased by 100x  <br><br>\n",
    "\n",
    " * The data populates dashboard that must be updated on a daily basis by 7am.<br>\n",
    " Use Apache Airflow <br><br>\n",
    "\n",
    " * The database needed to be accessed by 100+ people.<br>\n",
    " Store parquet files in AWS S3, give read access to users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
